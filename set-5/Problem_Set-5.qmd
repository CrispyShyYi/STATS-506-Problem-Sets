---
title: "Problem Set 5"
author: "Jialiang Wu"
format:
  html:
    theme: default
    page-layout: article
    code-fold: true
    code-summary: "Show the code"
    embed-resources: true
editor: visual
---

For source files and data, see my GitHub repo: [STATS-506-Problem-Sets-05](https://github.com/CrispyShyYi/STATS-506-Problem-Sets/tree/main/set-5)

## Problem 1

### problem 1-a

```{r p1a}
# S4 class
setClass("waldCI",
         slots = c(mean = "numeric",
                   sterr = "numeric",
                   level = "numeric"))


# Constructor
waldCI <- function(mean = NULL, sterr = NULL, lb = NULL, ub = NULL, level = 0.95){
  # 1: mean + sterr
  if(!is.null(mean) && !is.null(sterr)){
    new("waldCI", mean = mean, sterr = sterr, level = level)
  } 
  # lb + ub (+ CI)
  else if(!is.null(lb) && !is.null(ub)){
    # convert CI to mean + se
    z <- qnorm( (1 + level)/2 )
    m <- (lb + ub)/2
    se <- (ub - m)/z
    new("waldCI", mean = m, sterr = se, level = level)
  } 
  else {
    stop("must give mean+sterr or lb+ub")
  }
}

# Validator
setValidity("waldCI", function(object){

  if(object@sterr <= 0){
    return("standard error must be > 0")
  }
  if(object@level <= 0 || object@level >= 1){
    return("level must be in (0,1)")
  }
  
  lb <- lbCalc(object, object@level)
  ub <- ubCalc(object, object@level)
  
  if(lb > ub){
    return("lower bound cannot exceed upper bound")
  }

  if(!is.finite(lb) || !is.finite(ub)){
    return("bounds cannot be infinite")
  }

  return(TRUE)
})


# show
setGeneric("show", function(object, level=object@level, digits=3) standardGeneric("show"))
setMethod("show", "waldCI",
          function(object, level=object@level, digits=3){
            cat("Wald CI:",
                paste0("[", round(lbCalc(object, level), digits), ", ",
                       round(ubCalc(object, level), digits), "]"),
                " at level ", level, "\n")
          })


# Accessors
setGeneric("lb", function(object, level = object@level) standardGeneric("lb"))
setGeneric("ub", function(object, level = object@level) standardGeneric("ub"))
setGeneric("mean", function(object) standardGeneric("mean"))
setGeneric("sterr", function(object) standardGeneric("sterr"))

setGeneric("lb<-", function(object, level=object@level, value) standardGeneric("lb<-"))
setGeneric("ub<-", function(object, level=object@level, value) standardGeneric("ub<-"))
setGeneric("mean<-", function(object, value) standardGeneric("mean<-"))
setGeneric("sterr<-", function(object, value) standardGeneric("sterr<-"))

setGeneric("lb<-", function(object, level=object@level, value){
  standardGeneric("lb<-")
})
setGeneric("ub<-", function(object, level=object@level, value){
  standardGeneric("ub<-")
})

# expand CI function
lbCalc <- function(object, level = object@level){
  object@mean - qnorm((1 + level)/2) * object@sterr
}
ubCalc <- function(object, level = object@level){
  object@mean + qnorm((1 + level)/2) * object@sterr
}
setGeneric("mean<-", function(object, value){
  standardGeneric("mean<-")
})
setGeneric("sterr<-", function(object, value){
  standardGeneric("sterr<-")
})

# Setter
setMethod("lb", "waldCI", function(object,level) lbCalc(object, level))
setMethod("ub", "waldCI", function(object,level) ubCalc(object, level))
setMethod("mean", "waldCI", function(object) object@mean)
setMethod("sterr","waldCI", function(object) object@sterr)

setMethod("lb<-", "waldCI",
          function(object, level, value){
            z <- qnorm((1+level)/2)
            object@mean <- (value + ubCalc(object, level))/2
            object@sterr <- (ubCalc(object, level) - object@mean)/z
            validObject(object)
            object
          })

setMethod("ub<-", "waldCI",
          function(object, level, value){
            z <- qnorm((1+level)/2)
            object@mean <- (value + lbCalc(object, level))/2
            object@sterr <- (value - object@mean)/z
            validObject(object)
            object
          })

setMethod("mean<-", "waldCI",
          function(object, value){
            object@mean <- value
            validObject(object)
            object
          })

setMethod("sterr<-", "waldCI",
          function(object, value){
            object@sterr <- value
            validObject(object)
            object
          })



# contains
setGeneric("contains", function(object, value, level = object@level) standardGeneric("contains"))
setMethod("contains", "waldCI", function(object, value, level){
  lbCalc(object, level) <= value & value <= ubCalc(object, level)
})

# overlap
setGeneric("overlap", function(x, y, level = 0.95) standardGeneric("overlap"))
setMethod("overlap", c("waldCI", "waldCI"),
          function(x, y, level = 0.95){
            max(lbCalc(x, level), lbCalc(y, level)) <= min(ubCalc(x,level), ubCalc(y,level))
          })


# as.numeric
setMethod("as.numeric","waldCI",
          function(x, level = x@level){
            c(lbCalc(x, level), ubCalc(x, level))
          })


# transform
setGeneric("transform", function(object, f, level = object@level) standardGeneric("transform"))
setMethod("transform", c("waldCI", "function"),
          function(object, f, level = object@level){
            newlb <- f(lbCalc(object, level))
            newub <- f(ubCalc(object, level))
            waldCI(lb = newlb, ub = newub, level = level)
          })
```

### problem 1-b

```{r p1b}
# ci1
ci1 <- waldCI(lb = 17.2,
              ub = 24.7,
              level = 0.95)

# ci2
ci2 <- waldCI(mean = 13,
              sterr = 2.5)

# ci3
ci3 <- waldCI(lb = 27.43,
              ub = 39.22,
              level = 0.75)

# Evaluate
ci1
ci2
ci3

as.numeric(ci1)
as.numeric(ci2, .8)
as.numeric(ci3)

show(ci1, .9)
show(ci2, .8)
show(ci3, .75)

lb(ci2)
ub(ci2, .99)
mean(ci1)
sterr(ci3)

lb(ci2) <- 10.5
lb(ci2, .9) <- 10
mean(ci3) <- 34

contains(ci1, 17)
contains(ci2, 11, .9)
contains(ci3, 44)

overlap(ci1, ci2)
overlap(ci1, ci2, .99)

eci1 <- transform(ci1, exp)
eci1
show(eci1, .75)
mean(transform(ci2, sqrt))
```

### problem 1-c

```{r p1c}
try(waldCI(mean=10, sterr=-2))
try(waldCI(lb=5, ub=1))

try(waldCI(mean=Inf, sterr=2))       # mean infinite
try(waldCI(mean=10, sterr=Inf))      # sterr infinite
try(waldCI(mean=10, sterr=2, level=1)) # infinite z bound

ci <- waldCI(mean=10,sterr=2)
try(lb(ci) <- 200)
try(ub(ci,.9) <- -10)
```

## Problem 2

### load ATP Matches data

```{r setup_question2}
library(data.table)

ATP <- fread("https://raw.githubusercontent.com/JeffSackmann/tennis_atp/refs/heads/master/atp_matches_2019.csv")
```

### problem 2-a

In the ATP Matches dataset, the Davis Cup is recorded differently from regular ATP tournaments. Each Davis Cup tie (e.g., France vs Japan, Spain vs Russia) is assigned its own tourney_id. This means that if we simply count distinct(tourney_id), the Davis Cup will appear as many separate tournaments, which would artificially inflate the number of tournaments in 2019.

To address this, we need to group all tourney_id values that belong to the Davis Cup (those containing "2019-M-DC") and treat them as one single tournament. For the rest of the tournaments, we can safely count distinct tourney_id values directly.

Thus, the total number of tournaments in 2019 is calculated as:

Number of tournaments = distinct non–Davis Cup tourney_ids + 1 (for Davis Cup)

```{r p2a}
# Split into Davis Cup vs others
davis_ids <- unique(ATP[like(tourney_id, "2019-M-DC"), tourney_id])
other_ids  <- unique(ATP[!like(tourney_id, "2019-M-DC"), tourney_id])

# Final tournament count: all others + 1 for Davis Cup
n_tournaments <- length(other_ids) + 1

n_tournaments
```

**Answer:** There are 69 tournaments took place in 2019

### problem 2-b

The Laver Cup (tournament_id: 2019-9210) is a special team exhibition event (Team Europe vs Team World). Unlike standard ATP tournaments, it does not have a single final match (round == “F”) that produces an individual player champion. Also, the Davis Cup is a national team competition, not an individual tournament, which means the winner is the nation’s team, not an individual player. Instead, the winner is a team, determined by cumulative points across multiple singles and doubles matches.

Therefore, for Question 2-b (counting how many players won multiple tournaments and identifying the player(s) with the most titles), the Laver Cup and The Davis Cup should be excluded from the statistics.

```{r p2b}
# Exclude Davis Cup and Laver Cup
ATP_clean <- ATP[!like(tourney_id, "2019-M-DC") & tourney_id != "2019-9210"]

# Tournament winners (Final round winners)
tourney_winners <- unique(
  ATP_clean[round == "F", .(tourney_id, tourney_name, winner_id, winner_name)]
)

# Count titles per player
player_titles <- tourney_winners[, .(num_titles = .N), by = .(winner_id, winner_name)]

# Players with > 1 title
multiple_winners <- player_titles[num_titles > 1]

# display results
n_players_multiple <- nrow(multiple_winners)
max_titles <- max(player_titles$num_titles)

# display results
n_players_multiple
max_titles
```

**Answer:** There are 12 players won more than one tournament, and the most winning player won 5 tournaments.

### problem 2-c

```{r p2c}
# Summarize mean and median aces
aces_summary <- ATP[, .(
  mean_winner_aces  = base::mean(w_ace, na.rm = TRUE),
  mean_loser_aces   = base::mean(l_ace, na.rm = TRUE),
  median_winner_aces = stats::median(w_ace, na.rm = TRUE),
  median_loser_aces  = stats::median(l_ace, na.rm = TRUE)
)]

print(aces_summary)

# reshape long
aces_long <- melt(
  ATP[, .(Winner = w_ace, Loser = l_ace)],
  measure.vars = c("Winner", "Loser"),
  variable.name = "Role",
  value.name = "Aces"
)

library(ggplot2)
ggplot(aces_long, aes(x = Role, y = Aces, fill = Role)) +
  geom_boxplot(na.rm = TRUE) +
  labs(title = "Distribution of Aces: Winners vs Losers (2019)")
```

**Answer:** There is clear descriptive evidence that match winners tend to serve more aces than losers in 2019. While not a formal hypothesis test, the mean, median, and distribution comparisons all point in the same direction.

### problem 2-d

For each player, the win rate = number of matches won / total matches played

```{r p2d}
# Wins per player
wins <- ATP[, .(wins = .N), by = winner_name]

# Losses per player
losses <- ATP[, .(losses = .N), by = loser_name]

# merge wins & losses (full join)
player_stats <- merge(wins, losses,
                      by.x = "winner_name", by.y = "loser_name",
                      all = TRUE)

# rename + compute stats
player_stats[, player := winner_name]
player_stats[, winner_name := NULL]

player_stats[is.na(wins), wins := 0]
player_stats[is.na(losses), losses := 0]

player_stats[, total := wins + losses]
player_stats[, win_rate := wins / total]

player_stats <- player_stats[total >= 5]

# top players
top_players <- player_stats[win_rate == max(win_rate, na.rm = TRUE)]

top_players
```

**Answer:** As a result Rafael Nadal has the highest win-rate in tournament 2019.

## Problem 3

### laod NYTimes Covid data

```{r setup_question3}
covid <- fread("https://raw.githubusercontent.com/nytimes/covid-19-data/refs/heads/master/rolling-averages/us.csv")
```

### problem 3-a

```{r p3a}
# percentile cutoff
major_cutoff <- quantile(covid$cases_avg, probs = 0.95, na.rm = TRUE)
minor_cutoff <- quantile(covid$cases_avg, probs = 0.75, na.rm = TRUE)

covid_peaks <- covid[, {
  lag_case  <- shift(cases_avg, 1, type="lag")
  lead_case <- shift(cases_avg, 1, type="lead")

  is_peak <- cases_avg > lag_case & cases_avg > lead_case

  spike_type <- fifelse(
    is_peak & cases_avg >= major_cutoff, "Major spike",
    fifelse(is_peak & cases_avg >= minor_cutoff, "Minor spike", NA_character_)
  )

  .(date = date[!is.na(spike_type)],
    cases_avg = cases_avg[!is.na(spike_type)],
    spike_type = spike_type[!is.na(spike_type)])
}]


# count
peak_counts <- covid_peaks[, .(N = .N), by = spike_type][
  , label := paste0(spike_type, ": ", N)]

peak_counts

library(plotly)
highlight_labels <- covid_peaks[
  spike_type == "Major spike"
][order(-cases_avg)][1:5][
  , label := paste0(
    format(date, "%b %Y"),
    "\n",
    scales::comma(round(cases_avg)),
    " cases"
  )
]

# plotly
plot_ly() %>%
  add_lines(
    data = covid,
    x = ~date,
    y = ~cases_avg,
    line = list(width = 0.6, color = "grey30"),
    name = "cases avg"
  ) %>%
  add_markers(
    data = covid_peaks,
    x = ~date,
    y = ~cases_avg,
    color = ~spike_type,
    marker = list(size = ifelse(covid_peaks$spike_type=="Major spike", 10, 6), opacity = 0.85),
    hoverinfo = "text",
    text = ~paste(
      format(date, "%b %d %Y"),
      "<br>", spike_type,
      "<br>", scales::comma(round(cases_avg)), "cases"
    ),
    name = "spikes"
  ) %>%
  layout(
    title = "Identifying Major and Minor Spikes in US COVID-19 Cases",
    xaxis = list(title = ""),
    yaxis = list(title = "average new cases"),
    showlegend = TRUE
  )
```

**Answer:** Personally, I set a peak as major peak when the `cases_avg` is larger than the 95% percentiles, and a peak as minor peak when `cases_avg` is between 75% and 95% percentiles. And there are 2 major peaks and 26 minor peaks

### problem 3-b

```{r p3b}
url <- "https://raw.githubusercontent.com/nytimes/covid-19-data/refs/heads/master/rolling-averages/us-states.csv"
covid_states <- fread(url)
covid_states[, date := as.Date(date)]

#--------

# each state cases per 100k
cases_state_totals <- covid_states[
  , .(total_cases_per_100k = sum(cases_avg_per_100k, na.rm=TRUE)), by = state
][order(-total_cases_per_100k)]

# extreme
cases_extreme_states <- cases_state_totals[c(1, .N), state]

plot_data <- covid_states[state %in% cases_extreme_states]

# simple plotly version
plot_ly(plot_data,
        x = ~date, y = ~cases_avg_per_100k,
        color = ~state, type = 'scatter', mode = 'lines') %>%
  layout(
    title = "COVID-19 New Cases per 100,000 Residents",
    xaxis = list(title = ""),
    yaxis = list(title = "avg new cases per 100k"),
    legend = list(orientation = "h", x = 0.1, y = 1.1)
  )

#--------

# deaths per 100k total by state
deaths_state_totals <- covid_states[
  , .(total_deaths_per_100k = sum(deaths_avg_per_100k, na.rm = TRUE)), by = state
][order(-total_deaths_per_100k)]

# pick max and min state
deaths_extreme_states <- deaths_state_totals[c(1, .N), state]

plot_data <- covid_states[state %in% deaths_extreme_states & !is.na(deaths_avg_per_100k)]

# plotly line plot
plot_ly(plot_data,
        x = ~date, y = ~deaths_avg_per_100k,
        color = ~state, type = 'scatter', mode = 'lines') %>%
  layout(
    title = "COVID-19 deaths per 100,000 Residents",
    xaxis = list(title = ""),
    yaxis = list(title = "avg deaths per 100k"),
    legend = list(orientation = "h", x = 0.1, y = 1.1)
  )
```

**Answer:** the provided data set is the national series, where one row per day for the entire country. So we need another data set with state-level data. [NYTimes Covid Data - State Level](https://raw.githubusercontent.com/nytimes/covid-19-data/refs/heads/master/rolling-averages/us-states.csv).

First, use the variable `cases_avg_per_100k`. Compared with these two different stats, where Rhode Island has the highest overall new cases rates per population and Maine has the lowest overall new cases rates per population, there is no big trend difference between these two. However, we can tell at similar timestamps, the Rhode Island usually has larger peaks compared with Maine.

Second, use the variable `deaths_avg_per_100k`. Compared with these two different stats, where Rhode Island has the lowest overall deaths rates per population and Arizona has the highest overall deaths rates per population, the Rhode Island's deaths rate in population has a peak in 2022, while the deaths rate for Arizona has three to four peaks around 2020.6, 2021.2, 2022.1, and 2023.1.

### problem 3-c

```{r p3c}
threshold <- 20

# find first date when state hit substantial threshold
first_hits <- covid_states[cases_avg_per_100k >= threshold,
                           .(first_substantial = min(date)), by = state][order(first_substantial)]

# earliest 5 states
early_states <- first_hits[1:5, state]

# subset + join back
plot_data <- covid_states[state %in% early_states][first_hits, on = "state"][
  date >= first_substantial - 7 & date <= first_substantial + 21
][
  , days_since_first := as.integer(date - first_substantial)
]

# plot
p <- plot_ly(plot_data,
        x = ~days_since_first,
        y = ~cases_avg_per_100k,
        color = ~state,
        type = "scatter",
        mode = "lines"
)

# dashed line
p <- p %>%
  add_lines(showlegend = FALSE) %>%

  add_markers(data = plot_data[days_since_first == 0],
              size = 6,
              showlegend = FALSE) %>%

  layout(
    title = "Earliest States To See Sustained COVID-19 Spread",
    xaxis = list(title = "Days Since First Substantial Spread"),
    yaxis = list(title = "Avg New Cases per 100k"),
    shapes = list(
      list(type = "line", x0 = min(plot_data$days_since_first), x1 = max(plot_data$days_since_first),
           y0 = threshold, y1 = threshold, line = list(dash = "dash", color = "grey"))
    )
  )

p

```

**Answer:** To answer this question, I set a threshold, which is 20 `cases_avg_per_100k`, representing a state starts to experience Covid. And then find the first date every states first hit the threshold, and arrange in an increasing sequence, to imformally identify the first five states.
